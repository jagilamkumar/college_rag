import os
import streamlit as st
import speech_recognition as sr

from langchain_cohere import CohereEmbeddings, ChatCohere
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader

# --- ğŸ”‘ COHERE API KEY ---
os.environ["COHERE_API_KEY"] = "e8YGxF4rmdD14ghKD1UZATDY7a98zKcRO6x3JmfC"

# --- ğŸ“„ Load PDF File ---
pdf_path = "college_info.pdf"  # Make sure this is in your working directory
loader = PyMuPDFLoader(pdf_path)
documents = loader.load()

# --- âœ‚ï¸ Split Text into Chunks ---
splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
docs = splitter.split_documents(documents)

# --- ğŸ” Create Vector Store ---
embeddings = CohereEmbeddings(model="embed-english-v2.0")
vectorstore = FAISS.from_documents(docs, embeddings)

# --- ğŸ¤– Setup LLM RetrievalQA ---
llm = ChatCohere(model="command-r")
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(),
    return_source_documents=True
)

# --- ğŸ™ï¸ Voice Input Function ---
def recognize_speech_from_mic():
    recognizer = sr.Recognizer()
    mic = sr.Microphone()

    with mic as source:
        st.info("ğŸ¤ Listening... please speak clearly.")
        audio = recognizer.listen(source)

    try:
        text = recognizer.recognize_google(audio)
        st.success(f"ğŸ“ You said: {text}")
        return text
    except sr.UnknownValueError:
        st.error("Could not understand audio.")
    except sr.RequestError:
        st.error("API unavailable or quota exceeded.")

    return ""

# --- ğŸ–¥ï¸ Streamlit UI ---
st.set_page_config(page_title="College Chatbot", page_icon="ğŸ“")
st.markdown("<h1 style='text-align: center; color: navy;'>ğŸ“ College Info Chatbot</h1>", unsafe_allow_html=True)

# ğŸ“¥ Text Input or Voice Input
query = st.text_input("ğŸ’¬ Type your question about the college:")
use_mic = st.button("ğŸ™ï¸ Use Voice Instead")

if use_mic:
    query = recognize_speech_from_mic()

if query:
    with st.spinner("ğŸ” Searching..."):
        result = qa_chain(query)

    st.markdown("### âœ… Answer:")
    st.write(result["result"])

    with st.expander("ğŸ“„ Source Context"):
        for doc in result["source_documents"]:
            st.markdown(doc.page_content)

# --- Optional: Add a footer ---
st.markdown("""
<hr>
<div style='text-align: center; color: grey;'>
    Made with ğŸ’™ using Cohere + LangChain + Streamlit
</div>
""", unsafe_allow_html=True)
